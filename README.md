# Scalar-BackPropagation
* Gradient descent is an optimization algorithm used to find the values of parameters (weights) of a function (Neural network) that minimizes a cost function (loss).

## Binary classification ##
* 2 inputs
* 1 hiden layer with 2 neurons
* output layer with 1 neuron

## Multiclass classification (4-class) ##
* 2 inputs
* 1 hinnden layer with 2 neurons
* output layer with 4 neurons

## Notations ##
* a = x * w
* h = activation(a)

